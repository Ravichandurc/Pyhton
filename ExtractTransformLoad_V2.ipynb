{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0221ENSkillsNetwork899-2023-01-01\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Extract Transform Load (ETL) Lab**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "\n",
    "-   Read CSV and JSON file types.\n",
    "-   Extract data from the above file types.\n",
    "-   Transform data.\n",
    "-   Save the transformed data in a ready-to-load format which data engineers can use to load into an RDBMS.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required modules and functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob                         # this module helps in selecting files \n",
    "import pandas as pd                 # this module helps in processing CSV files\n",
    "import xml.etree.ElementTree as ET  # this module helps in processing XML files.\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/source.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!unzip source.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpfile    = \"temp.tmp\"               # file used to store all extracted data\n",
    "logfile    = \"logfile.txt\"            # all event logs will be stored in this file\n",
    "targetfile = \"transformed_data.csv\"   # file where transformed data is stored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV Extract Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_csv(file_to_process):\n",
    "    dataframe = pd.read_csv(file_to_process)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON Extract Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_json(file_to_process):\n",
    "    dataframe = pd.read_json(file_to_process,lines=True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XML Extract Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_xml(file_to_process):\n",
    "    dataframe = pd.DataFrame(columns=[\"name\", \"height\", \"weight\"])\n",
    "    tree = ET.parse(file_to_process)\n",
    "    root = tree.getroot()\n",
    "    for person in root:\n",
    "        name = person.find(\"name\").text\n",
    "        height = float(person.find(\"height\").text)\n",
    "        weight = float(person.find(\"weight\").text)\n",
    "        dataframe = dataframe.append({\"name\":name, \"height\":height, \"weight\":weight}, ignore_index=True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    extracted_data = pd.DataFrame(columns=['name','height','weight']) # create an empty data frame to hold extracted data\n",
    "    \n",
    "    #process all csv files\n",
    "    for csvfile in glob.glob(\"*.csv\"):\n",
    "        extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n",
    "        \n",
    "    #process all json files\n",
    "    for jsonfile in glob.glob(\"*.json\"):\n",
    "        extracted_data = extracted_data.append(extract_from_json(jsonfile), ignore_index=True)\n",
    "    \n",
    "    #process all xml files\n",
    "    for xmlfile in glob.glob(\"*.xml\"):\n",
    "        extracted_data = extracted_data.append(extract_from_xml(xmlfile), ignore_index=True)\n",
    "        \n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transform function does the following tasks.\n",
    "\n",
    "1.  Convert height which is in inches to millimeter\n",
    "2.  Convert weight which is in pounds to kilograms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transform(data):\n",
    "#         #Convert height which is in inches to millimeter\n",
    "#         #Convert the datatype of the column into float\n",
    "#         #data.height = data.height.astype(float)\n",
    "#         #Convert inches to meters and round off to two decimals(one inch is 0.0254 meters)\n",
    "#         data['height'] = round(data.height * 0.0254,2)\n",
    "        \n",
    "#         #Convert weight which is in pounds to kilograms\n",
    "#         #Convert the datatype of the column into float\n",
    "#         #data.weight = data.weight.astype(float)\n",
    "#         #Convert pounds to kilograms and round off to two decimals(one pound is 0.45359237 kilograms)\n",
    "#         data['weight'] = round(data.weight * 0.45359237,2)\n",
    "#         return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data):\n",
    "    # Convert height which is in inches to millimeters\n",
    "    # Convert inches to meters and round off to two decimals (one inch is 0.0254 meters)\n",
    "    data['height'] = data['height'].apply(lambda x: round(x * 0.0254, 2))\n",
    "\n",
    "    # Convert weight which is in pounds to kilograms\n",
    "    # Convert pounds to kilograms and round off to two decimals (one pound is 0.45359237 kilograms)\n",
    "    data['weight'] = data['weight'].apply(lambda x: round(x * 0.45359237, 2))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(targetfile,data_to_load):\n",
    "    data_to_load.to_csv(targetfile)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(message):\n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second\n",
    "    now = datetime.now() # get current timestamp\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    with open(\"logfile.txt\",\"a\") as f:\n",
    "        f.write(timestamp + ',' + message + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running ETL Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log(\"ETL Job Started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Futurense\\AppData\\Local\\Temp\\ipykernel_9648\\1191520049.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n",
      "C:\\Users\\Futurense\\AppData\\Local\\Temp\\ipykernel_9648\\1191520049.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n",
      "C:\\Users\\Futurense\\AppData\\Local\\Temp\\ipykernel_9648\\1191520049.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n",
      "C:\\Users\\Futurense\\AppData\\Local\\Temp\\ipykernel_9648\\1191520049.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n",
      "C:\\Users\\Futurense\\AppData\\Local\\Temp\\ipykernel_9648\\1191520049.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>CLIENTNUM</th>\n",
       "      <th>Attrition_Flag</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>...</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>768805383.0</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>45.0</td>\n",
       "      <td>M</td>\n",
       "      <td>3.0</td>\n",
       "      <td>High School</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>818770008.0</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>49.0</td>\n",
       "      <td>F</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>713982108.0</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>51.0</td>\n",
       "      <td>M</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>769911858.0</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>40.0</td>\n",
       "      <td>F</td>\n",
       "      <td>4.0</td>\n",
       "      <td>High School</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>709106358.0</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>40.0</td>\n",
       "      <td>M</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Uneducated</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850733</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>95.1</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.77</td>\n",
       "      <td>1.513</td>\n",
       "      <td>16.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850734</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>351</td>\n",
       "      <td>264.0</td>\n",
       "      <td>4.22</td>\n",
       "      <td>3.17</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850735</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>145</td>\n",
       "      <td>175.0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>2.77</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850736</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>301</td>\n",
       "      <td>335.0</td>\n",
       "      <td>3.54</td>\n",
       "      <td>3.57</td>\n",
       "      <td>14.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850737</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>121</td>\n",
       "      <td>109.0</td>\n",
       "      <td>4.11</td>\n",
       "      <td>2.78</td>\n",
       "      <td>18.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>850738 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       name height weight    CLIENTNUM     Attrition_Flag  Customer_Age  \\\n",
       "0       NaN    NaN    NaN  768805383.0  Existing Customer          45.0   \n",
       "1       NaN    NaN    NaN  818770008.0  Existing Customer          49.0   \n",
       "2       NaN    NaN    NaN  713982108.0  Existing Customer          51.0   \n",
       "3       NaN    NaN    NaN  769911858.0  Existing Customer          40.0   \n",
       "4       NaN    NaN    NaN  709106358.0  Existing Customer          40.0   \n",
       "...     ...    ...    ...          ...                ...           ...   \n",
       "850733  NaN    NaN    NaN          NaN                NaN           NaN   \n",
       "850734  NaN    NaN    NaN          NaN                NaN           NaN   \n",
       "850735  NaN    NaN    NaN          NaN                NaN           NaN   \n",
       "850736  NaN    NaN    NaN          NaN                NaN           NaN   \n",
       "850737  NaN    NaN    NaN          NaN                NaN           NaN   \n",
       "\n",
       "       Gender  Dependent_count Education_Level Marital_Status  ...  cyl  disp  \\\n",
       "0           M              3.0     High School        Married  ...  NaN   NaN   \n",
       "1           F              5.0        Graduate         Single  ...  NaN   NaN   \n",
       "2           M              3.0        Graduate        Married  ...  NaN   NaN   \n",
       "3           F              4.0     High School        Unknown  ...  NaN   NaN   \n",
       "4           M              3.0      Uneducated        Married  ...  NaN   NaN   \n",
       "...       ...              ...             ...            ...  ...  ...   ...   \n",
       "850733    NaN              NaN             NaN            NaN  ...  4.0  95.1   \n",
       "850734    NaN              NaN             NaN            NaN  ...  8.0   351   \n",
       "850735    NaN              NaN             NaN            NaN  ...  6.0   145   \n",
       "850736    NaN              NaN             NaN            NaN  ...  8.0   301   \n",
       "850737    NaN              NaN             NaN            NaN  ...  4.0   121   \n",
       "\n",
       "           hp  drat     wt  qsec   vs   am  gear  carb  \n",
       "0         NaN   NaN    NaN   NaN  NaN  NaN   NaN   NaN  \n",
       "1         NaN   NaN    NaN   NaN  NaN  NaN   NaN   NaN  \n",
       "2         NaN   NaN    NaN   NaN  NaN  NaN   NaN   NaN  \n",
       "3         NaN   NaN    NaN   NaN  NaN  NaN   NaN   NaN  \n",
       "4         NaN   NaN    NaN   NaN  NaN  NaN   NaN   NaN  \n",
       "...       ...   ...    ...   ...  ...  ...   ...   ...  \n",
       "850733  113.0  3.77  1.513  16.9  1.0  1.0   5.0   2.0  \n",
       "850734  264.0  4.22   3.17  14.5  0.0  1.0   5.0   4.0  \n",
       "850735  175.0  3.62   2.77  15.5  0.0  1.0   5.0   6.0  \n",
       "850736  335.0  3.54   3.57  14.6  0.0  1.0   5.0   8.0  \n",
       "850737  109.0  4.11   2.78  18.6  1.0  1.0   4.0   2.0  \n",
       "\n",
       "[850738 rows x 56 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log(\"Extract phase Started\")\n",
    "extracted_data = extract()\n",
    "log(\"Extract phase Ended\")\n",
    "extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>CLIENTNUM</th>\n",
       "      <th>Attrition_Flag</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>...</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>768805383.0</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>45.0</td>\n",
       "      <td>M</td>\n",
       "      <td>3.0</td>\n",
       "      <td>High School</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>818770008.0</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>49.0</td>\n",
       "      <td>F</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>713982108.0</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>51.0</td>\n",
       "      <td>M</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>769911858.0</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>40.0</td>\n",
       "      <td>F</td>\n",
       "      <td>4.0</td>\n",
       "      <td>High School</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>709106358.0</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>40.0</td>\n",
       "      <td>M</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Uneducated</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850733</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>95.1</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.77</td>\n",
       "      <td>1.513</td>\n",
       "      <td>16.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850734</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>351</td>\n",
       "      <td>264.0</td>\n",
       "      <td>4.22</td>\n",
       "      <td>3.17</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850735</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>145</td>\n",
       "      <td>175.0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>2.77</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850736</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>301</td>\n",
       "      <td>335.0</td>\n",
       "      <td>3.54</td>\n",
       "      <td>3.57</td>\n",
       "      <td>14.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850737</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>121</td>\n",
       "      <td>109.0</td>\n",
       "      <td>4.11</td>\n",
       "      <td>2.78</td>\n",
       "      <td>18.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>850738 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  height  weight    CLIENTNUM     Attrition_Flag  Customer_Age  \\\n",
       "0       NaN     NaN     NaN  768805383.0  Existing Customer          45.0   \n",
       "1       NaN     NaN     NaN  818770008.0  Existing Customer          49.0   \n",
       "2       NaN     NaN     NaN  713982108.0  Existing Customer          51.0   \n",
       "3       NaN     NaN     NaN  769911858.0  Existing Customer          40.0   \n",
       "4       NaN     NaN     NaN  709106358.0  Existing Customer          40.0   \n",
       "...     ...     ...     ...          ...                ...           ...   \n",
       "850733  NaN     NaN     NaN          NaN                NaN           NaN   \n",
       "850734  NaN     NaN     NaN          NaN                NaN           NaN   \n",
       "850735  NaN     NaN     NaN          NaN                NaN           NaN   \n",
       "850736  NaN     NaN     NaN          NaN                NaN           NaN   \n",
       "850737  NaN     NaN     NaN          NaN                NaN           NaN   \n",
       "\n",
       "       Gender  Dependent_count Education_Level Marital_Status  ...  cyl  disp  \\\n",
       "0           M              3.0     High School        Married  ...  NaN   NaN   \n",
       "1           F              5.0        Graduate         Single  ...  NaN   NaN   \n",
       "2           M              3.0        Graduate        Married  ...  NaN   NaN   \n",
       "3           F              4.0     High School        Unknown  ...  NaN   NaN   \n",
       "4           M              3.0      Uneducated        Married  ...  NaN   NaN   \n",
       "...       ...              ...             ...            ...  ...  ...   ...   \n",
       "850733    NaN              NaN             NaN            NaN  ...  4.0  95.1   \n",
       "850734    NaN              NaN             NaN            NaN  ...  8.0   351   \n",
       "850735    NaN              NaN             NaN            NaN  ...  6.0   145   \n",
       "850736    NaN              NaN             NaN            NaN  ...  8.0   301   \n",
       "850737    NaN              NaN             NaN            NaN  ...  4.0   121   \n",
       "\n",
       "           hp  drat     wt  qsec   vs   am  gear  carb  \n",
       "0         NaN   NaN    NaN   NaN  NaN  NaN   NaN   NaN  \n",
       "1         NaN   NaN    NaN   NaN  NaN  NaN   NaN   NaN  \n",
       "2         NaN   NaN    NaN   NaN  NaN  NaN   NaN   NaN  \n",
       "3         NaN   NaN    NaN   NaN  NaN  NaN   NaN   NaN  \n",
       "4         NaN   NaN    NaN   NaN  NaN  NaN   NaN   NaN  \n",
       "...       ...   ...    ...   ...  ...  ...   ...   ...  \n",
       "850733  113.0  3.77  1.513  16.9  1.0  1.0   5.0   2.0  \n",
       "850734  264.0  4.22   3.17  14.5  0.0  1.0   5.0   4.0  \n",
       "850735  175.0  3.62   2.77  15.5  0.0  1.0   5.0   6.0  \n",
       "850736  335.0  3.54   3.57  14.6  0.0  1.0   5.0   8.0  \n",
       "850737  109.0  4.11   2.78  18.6  1.0  1.0   4.0   2.0  \n",
       "\n",
       "[850738 rows x 56 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log(\"Transform phase Started\")\n",
    "transformed_data = transform(extracted_data)\n",
    "log(\"Transform phase Ended\")\n",
    "transformed_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "log(\"Load phase Started\")\n",
    "load(targetfile,transformed_data)\n",
    "log(\"Load phase Ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log(\"ETL Job Ended\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the example above complete the exercise below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/datasource.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/datasource.zip\"\n",
    "\n",
    "response = requests.get(url)\n",
    "zip_file_path = \"datasource.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/datasource.zip\"\n",
    "\n",
    "response = requests.get(url)\n",
    "zip_file = io.BytesIO(response.content)\n",
    "\n",
    "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"datasource\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Futurense\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  datasource.zip\n",
      "  inflating: dealership_data/used_car_prices1.csv  \n",
      "  inflating: dealership_data/used_car_prices2.csv  \n",
      "  inflating: dealership_data/used_car_prices3.csv  \n",
      "  inflating: dealership_data/used_car_prices1.json  \n",
      "  inflating: dealership_data/used_car_prices2.json  \n",
      "  inflating: dealership_data/used_car_prices3.json  \n",
      "  inflating: dealership_data/used_car_prices1.xml  \n",
      "  inflating: dealership_data/used_car_prices2.xml  \n",
      "  inflating: dealership_data/used_car_prices3.xml  \n"
     ]
    }
   ],
   "source": [
    "!unzip datasource.zip -d dealership_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `dealership_data` contains CSV, JSON, and XML files for used car data which contain features named `car_model`, `year_of_manufacture`, `price`, and `fuel`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpfile    = \"dealership_temp.tmp\"               # file used to store all extracted data\n",
    "logfile    = \"dealership_logfile.txt\"            # all event logs will be stored in this file\n",
    "targetfile = \"dealership_transformed_data.csv\"   # file where transformed data is stored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: CSV Extract Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the CSV extract function below\n",
    "\n",
    "\n",
    "\n",
    "def extract_from_csv(file_to_process):\n",
    "    dataframe = pd.read_csv(file_to_process)\n",
    "    return dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "    \n",
    "```\n",
    "    \n",
    "def extract_from_csv(file_to_process):\n",
    "    dataframe = pd.read_csv(file_to_process)\n",
    "    return dataframe\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: JSON Extract Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the JSON extract function below\n",
    "\n",
    "\n",
    "def extract_from_json(file_to_process):\n",
    "    dataframe = pd.read_json(file_to_process,lines=True)\n",
    "    return dataframe\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "    \n",
    "```\n",
    "    \n",
    "def extract_from_json(file_to_process):\n",
    "    dataframe = pd.read_json(file_to_process,lines=True)\n",
    "    return dataframe\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: XML Extract Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the XML extract function below, it is the same as the xml extract function above but the column names need to be renamed.\n",
    "def extract_from_xml(file_to_process):\n",
    "    dataframe = pd.DataFrame(columns=[\"name\", \"height\", \"weight\"])\n",
    "    tree = ET.parse(file_to_process)\n",
    "    root = tree.getroot()\n",
    "    for person in root:\n",
    "        name = person.find(\"name\").text\n",
    "        height = float(person.find(\"height\").text)\n",
    "        weight = float(person.find(\"weight\").text)\n",
    "        dataframe = dataframe.append({\"name\":name, \"height\":height, \"weight\":weight}, ignore_index=True)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "    \n",
    "```\n",
    "    \n",
    "def extract_from_xml(file_to_process):\n",
    "    dataframe = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel'])\n",
    "    tree = ET.parse(file_to_process)\n",
    "    root = tree.getroot()\n",
    "    for person in root:\n",
    "        car_model = person.find(\"car_model\").text\n",
    "        year_of_manufacture = int(person.find(\"year_of_manufacture\").text)\n",
    "        price = float(person.find(\"price\").text)\n",
    "        fuel = person.find(\"fuel\").text\n",
    "        dataframe = dataframe.append({\"car_model\":car_model, \"year_of_manufacture\":year_of_manufacture, \"price\":price, \"fuel\":fuel}, ignore_index=True)\n",
    "    return dataframe\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Extract Function\n",
    "\n",
    "Call the specific extract functions you created above by replacing the `ADD_FUNCTION_CALL` with the proper function call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    extracted_data = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel']) # create an empty data frame to hold extracted data\n",
    "    \n",
    "    #process all csv files\n",
    "    for csvfile in glob.glob(\"dealership_data/*.csv\"):\n",
    "        extracted_data = extracted_data.append('ADD_FUNCTION_CALL', ignore_index=True)\n",
    "        \n",
    "    #process all json files\n",
    "    for jsonfile in glob.glob(\"dealership_data/*.json\"):\n",
    "        extracted_data = extracted_data.append('ADD_FUNCTION_CALL', ignore_index=True)\n",
    "    \n",
    "    #process all xml files\n",
    "    for xmlfile in glob.glob(\"dealership_data/*.xml\"):\n",
    "        extracted_data = extracted_data.append('ADD_FUNCTION_CALL', ignore_index=True)\n",
    "        \n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "    \n",
    "```\n",
    "    \n",
    "def extract():\n",
    "    extracted_data = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel']) # create an empty data frame to hold extracted data\n",
    "    \n",
    "    #process all csv files\n",
    "    for csvfile in glob.glob(\"dealership_data/*.csv\"):\n",
    "        extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n",
    "        \n",
    "    #process all json files\n",
    "    for jsonfile in glob.glob(\"dealership_data/*.json\"):\n",
    "        extracted_data = extracted_data.append(extract_from_json(jsonfile), ignore_index=True)\n",
    "    \n",
    "    #process all xml files\n",
    "    for xmlfile in glob.glob(\"dealership_data/*.xml\"):\n",
    "        extracted_data = extracted_data.append(extract_from_xml(xmlfile), ignore_index=True)\n",
    "        \n",
    "    return extracted_data\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Transform\n",
    "\n",
    "Round the `price` columns to 2 decimal places\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the transform function below\n",
    "\n",
    "\n",
    "def transform(data):\n",
    "    # Convert height which is in inches to millimeters\n",
    "    # Convert inches to meters and round off to two decimals (one inch is 0.0254 meters)\n",
    "    data['price'] = data['price'].apply(lambda x: round(x * 0.0254, 2))\n",
    "\n",
    "    # Convert weight which is in pounds to kilograms\n",
    "    # Convert pounds to kilograms and round off to two decimals (one pound is 0.45359237 kilograms)\n",
    "    #data['weight'] = data['weight'].apply(lambda x: round(x * 0.45359237, 2))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "    \n",
    "```\n",
    "\n",
    "def transform(data):\n",
    "        data['price'] = round(data.price, 2)\n",
    "        return data\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: Load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the load function below\n",
    "\n",
    "def load(targetfile,data_to_load):\n",
    "    data_to_load.to_csv(targetfile)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "    \n",
    "```\n",
    "\n",
    "def load(targetfile,data_to_load):\n",
    "    data_to_load.to_csv(targetfile)  \n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: Log\n",
    "\n",
    "Make sure to change the name of the logfile to the one specified in the set paths section. Change the timestamp order to Hour-Minute-Second-Monthname-Day-Year.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the log function below\n",
    "def log(message):\n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second\n",
    "    now = datetime.now() # get current timestamp\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    with open(\"logfile.txt\",\"a\") as f:\n",
    "        f.write(timestamp + ',' + message + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "    \n",
    "```\n",
    "\n",
    "def log(message):\n",
    "    timestamp_format = '%H:%M:%S-%h-%d-%Y' #Hour-Minute-Second-MonthName-Day-Year\n",
    "    now = datetime.now() # get current timestamp\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    with open(\"dealership_logfile.txt\",\"a\") as f:\n",
    "        f.write(timestamp + ',' + message + '\\n') \n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running ETL Process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8: ETL Process\n",
    "\n",
    "Run all functions to extract, transform, and load the data. Make sure to log all events using the `log` function. Place your code under each comment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Futurense\\AppData\\Local\\Temp\\ipykernel_7840\\2287192832.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  extracted_data = extracted_data.append('ADD_FUNCTION_CALL', ignore_index=True)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'str'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Log that you have started the ETL process\u001b[39;00m\n\u001b[0;32m      3\u001b[0m log(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtract phase Started\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m extracted_data \u001b[38;5;241m=\u001b[39m \u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m log(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtract phase Ended\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m extracted_data\n",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m, in \u001b[0;36mextract\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#process all csv files\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m csvfile \u001b[38;5;129;01min\u001b[39;00m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdealership_data/*.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m----> 6\u001b[0m     extracted_data \u001b[38;5;241m=\u001b[39m \u001b[43mextracted_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mADD_FUNCTION_CALL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#process all json files\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m jsonfile \u001b[38;5;129;01min\u001b[39;00m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdealership_data/*.json\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:9768\u001b[0m, in \u001b[0;36mDataFrame.append\u001b[1;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[0;32m   9665\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   9666\u001b[0m \u001b[38;5;124;03mAppend rows of `other` to the end of caller, returning a new object.\u001b[39;00m\n\u001b[0;32m   9667\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9758\u001b[0m \u001b[38;5;124;03m4  4\u001b[39;00m\n\u001b[0;32m   9759\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   9760\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   9761\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe frame.append method is deprecated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   9762\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand will be removed from pandas in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9765\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   9766\u001b[0m )\n\u001b[1;32m-> 9768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_append\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:9808\u001b[0m, in \u001b[0;36mDataFrame._append\u001b[1;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[0;32m   9805\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   9806\u001b[0m     to_concat \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m, other]\n\u001b[1;32m-> 9808\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   9809\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_concat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9810\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9811\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9812\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9813\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   9814\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:368\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat\u001b[39m(\n\u001b[0;32m    148\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    158\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m    Concatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03m    1   3   4\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:458\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (ABCSeries, ABCDataFrame)):\n\u001b[0;32m    454\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    455\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot concatenate object of type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    456\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly Series and DataFrame objs are valid\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    457\u001b[0m         )\n\u001b[1;32m--> 458\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m    460\u001b[0m     ndims\u001b[38;5;241m.\u001b[39madd(obj\u001b[38;5;241m.\u001b[39mndim)\n\u001b[0;32m    462\u001b[0m \u001b[38;5;66;03m# get the sample\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;66;03m# want the highest ndim that we have, and must be non-empty\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;66;03m# unless all objs are empty\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'str'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "# Log that you have started the ETL process\n",
    "\n",
    "log(\"Extract phase Started\")\n",
    "extracted_data = extract()\n",
    "log(\"Extract phase Ended\")\n",
    "extracted_data\n",
    "\n",
    "\n",
    "log(\"Transform phase Started\")\n",
    "transformed_data = transform(extracted_data)\n",
    "log(\"Transform phase Ended\")\n",
    "transformed_data \n",
    "\n",
    "\n",
    "\n",
    "log(\"Load phase Started\")\n",
    "load(targetfile,transformed_data)\n",
    "log(\"Load phase Ended\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Log that you have started the Extract step\n",
    "\n",
    "# Call the Extract function\n",
    "\n",
    "# Log that you have completed the Extract step\n",
    "\n",
    "\n",
    "# Log that you have started the Transform step\n",
    "\n",
    "# Call the Transform function\n",
    "\n",
    "# Log that you have completed the Transform step\n",
    "\n",
    "\n",
    "# Log that you have started the Load step\n",
    "\n",
    "# Call the Load function\n",
    "\n",
    "# Log that you have completed the Load step\n",
    "\n",
    "\n",
    "# Log that you have completed the ETL process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "    \n",
    "```\n",
    "\n",
    "log(\"ETL Job Started\")\n",
    "\n",
    "log(\"Extract phase Started\")\n",
    "extracted_data = extract()\n",
    "log(\"Extract phase Ended\")\n",
    "\n",
    "log(\"Transform phase Started\")\n",
    "transformed_data = transform(extracted_data)\n",
    "log(\"Transform phase Ended\")\n",
    "\n",
    "log(\"Load phase Started\")\n",
    "load(targetfile,transformed_data)\n",
    "log(\"Load phase Ended\")\n",
    "\n",
    "log(\"ETL Job Ended\")\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ramesh Sannareddy\n",
    "\n",
    "Joseph Santarcangelo\n",
    "\n",
    "Azim Hirjani\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Date (YYYY-MM-DD) | Version | Changed By        | Change Description                 |\n",
    "| ----------------- | ------- | ----------------- | ---------------------------------- |\n",
    "| 2020-11-25        | 0.1     | Ramesh Sannareddy | Created initial version of the lab |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Copyright © 2020 IBM Corporation. This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0221ENSkillsNetwork899-2023-01-01&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork-23455645&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
